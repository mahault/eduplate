{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahault/eduplate/blob/main/Eduplate_toy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic toy example - full inference loop and explanation"
      ],
      "metadata": {
        "id": "RbVEmHgGWPtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgmpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFLo5vLnTz4N",
        "outputId": "17f30056-b0b1-4fe6-e1e1-2c95de0612c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pgmpy\n",
            "  Downloading pgmpy-0.1.25-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/2.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.0.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.3.0+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->pgmpy)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->pgmpy)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->pgmpy)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->pgmpy)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->pgmpy)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->pgmpy)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->pgmpy)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->pgmpy)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->pgmpy)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->pgmpy)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->pgmpy)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->pgmpy)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pgmpy\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pgmpy-0.1.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define the Bayesian Network\n",
        "Based on the provided graph, the variables are:\n",
        "\n",
        "\n",
        "\n",
        "*   Active Ing (Active Ingredient)\n",
        "* Food\n",
        "* Quantity\n",
        "* Effectiveness\n",
        "* Types of Effects\n",
        "\n",
        "We will use the pgmpy library to define the Bayesian Network.\n",
        "\n"
      ],
      "metadata": {
        "id": "Afy5_czAT7lV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EczYVz0TuqH"
      },
      "outputs": [],
      "source": [
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Define the structure of the Bayesian Network\n",
        "model = BayesianNetwork([('ActiveIng', 'Effectiveness'),\n",
        "                         ('Food', 'Effectiveness'),\n",
        "                         ('Quantity', 'Effectiveness'),\n",
        "                         ('Effectiveness', 'TypesOfEffects')])\n",
        "\n",
        "# Define the CPDs (using dummy probabilities for illustration)\n",
        "cpd_active_ing = TabularCPD(variable='ActiveIng', variable_card=2, values=[[0.7], [0.3]])\n",
        "cpd_food = TabularCPD(variable='Food', variable_card=2, values=[[0.6], [0.4]])\n",
        "cpd_quantity = TabularCPD(variable='Quantity', variable_card=2, values=[[0.5], [0.5]])\n",
        "\n",
        "cpd_effectiveness = TabularCPD(variable='Effectiveness', variable_card=2,\n",
        "                               values=[[0.95, 0.8, 0.8, 0.6, 0.8, 0.6, 0.6, 0.2],\n",
        "                                       [0.05, 0.2, 0.2, 0.4, 0.2, 0.4, 0.4, 0.8]],\n",
        "                               evidence=['ActiveIng', 'Food', 'Quantity'],\n",
        "                               evidence_card=[2, 2, 2])\n",
        "\n",
        "cpd_types_of_effects = TabularCPD(variable='TypesOfEffects', variable_card=2,\n",
        "                                  values=[[0.9, 0.8],  # P(TypesOfEffects=0 | Effectiveness=0) and P(TypesOfEffects=0 | Effectiveness=1)\n",
        "                                          [0.1, 0.2]], # P(TypesOfEffects=1 | Effectiveness=0) and P(TypesOfEffects=1 | Effectiveness=1)\n",
        "                                  evidence=['Effectiveness'],\n",
        "                                  evidence_card=[2])\n",
        "\n",
        "# Add the CPDs to the model\n",
        "model.add_cpds(cpd_active_ing, cpd_food, cpd_quantity, cpd_effectiveness, cpd_types_of_effects)\n",
        "\n",
        "# Check if the model is valid\n",
        "assert model.check_model()\n",
        "\n",
        "# Define the inference object\n",
        "inference = VariableElimination(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HmWn1oqETxWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data Preprocessing\n",
        "\n",
        "Extract relevant facts from the transcript. For simplicity, let's assume we have a dictionary of extracted facts."
      ],
      "metadata": {
        "id": "MwJatrCGUQKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example observations extracted from the transcript\n",
        "observations = {'ActiveIng': 1, 'Food': 0, 'Quantity': 1}\n"
      ],
      "metadata": {
        "id": "0LD3Lx1zUSez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Perform Inference and Generate Explanations\n",
        "\n",
        "Perform inference to compute the probability of Effectiveness and TypesOfEffects."
      ],
      "metadata": {
        "id": "NOv0e4HNUZ59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference to find the probability of Effectiveness\n",
        "prob_effectiveness = inference.query(variables=['Effectiveness'], evidence=observations)\n",
        "print(f\"Probability of Effectiveness: {prob_effectiveness}\")\n",
        "\n",
        "# Perform inference to find the probability of Types of Effects\n",
        "prob_types_of_effects = inference.query(variables=['TypesOfEffects'], evidence=observations)\n",
        "print(f\"Probability of Types of Effects: {prob_types_of_effects}\")\n",
        "\n",
        "# Generate explanations\n",
        "explanation_effectiveness = f\"Given the Active Ingredient, Food, and Quantity, the probability of Effectiveness being high is {prob_effectiveness.values[1]:.2f}.\"\n",
        "explanation_types_of_effects = f\"Given the Effectiveness, the probability of having significant Types of Effects is {prob_types_of_effects.values[1]:.2f}.\"\n",
        "\n",
        "print(f\"Explanation for Effectiveness: {explanation_effectiveness}\")\n",
        "print(f\"Explanation for Types of Effects: {explanation_types_of_effects}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv30eEM6UWek",
        "outputId": "66cc4882-39d7-41db-a77e-52aa55dd6598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of Effectiveness: +------------------+----------------------+\n",
            "| Effectiveness    |   phi(Effectiveness) |\n",
            "+==================+======================+\n",
            "| Effectiveness(0) |               0.6000 |\n",
            "+------------------+----------------------+\n",
            "| Effectiveness(1) |               0.4000 |\n",
            "+------------------+----------------------+\n",
            "Probability of Types of Effects: +-------------------+-----------------------+\n",
            "| TypesOfEffects    |   phi(TypesOfEffects) |\n",
            "+===================+=======================+\n",
            "| TypesOfEffects(0) |                0.8600 |\n",
            "+-------------------+-----------------------+\n",
            "| TypesOfEffects(1) |                0.1400 |\n",
            "+-------------------+-----------------------+\n",
            "Explanation for Effectiveness: Given the Active Ingredient, Food, and Quantity, the probability of Effectiveness being high is 0.40.\n",
            "Explanation for Types of Effects: Given the Effectiveness, the probability of having significant Types of Effects is 0.14.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V-ZdcX_gUZsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now let's say you want to learn the values of the probabilities rather than prespecify them"
      ],
      "metadata": {
        "id": "Tuoezfc6WGzF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ppEaR70WOnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define the Network Structure\n",
        "\n",
        "First, define the network structure as done previously."
      ],
      "metadata": {
        "id": "HOFy5mcNWYZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Define the structure of the Bayesian Network\n",
        "model = BayesianNetwork([('ActiveIng', 'Effectiveness'),\n",
        "                         ('Food', 'Effectiveness'),\n",
        "                         ('Quantity', 'Effectiveness'),\n",
        "                         ('Effectiveness', 'TypesOfEffects'),\n",
        "                         ('ActiveIng', 'TypesOfEffects'),\n",
        "                         ('Food', 'TypesOfEffects')])"
      ],
      "metadata": {
        "id": "-YT6ey1rW2R1"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Prepare the Data\n",
        "\n",
        "Assume you have a dataset in a CSV file. Load this data into a pandas DataFrame.\n"
      ],
      "metadata": {
        "id": "2rfyOkbJWbaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "# data = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'ActiveIng': [1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
        "    'Food': [0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
        "    'Quantity': [1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1],\n",
        "    'Effectiveness': [1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
        "    'TypesOfEffects': [0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
        "})\n"
      ],
      "metadata": {
        "id": "RcWH1LcSWZPs"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Parameter Learning\n",
        "\n",
        "Use the MaximumLikelihoodEstimator to learn the CPDs from the data."
      ],
      "metadata": {
        "id": "BNFjOfCTWlFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "\n",
        "\n",
        "# Fit the model using MaximumLikelihoodEstimator\n",
        "model.fit(data, estimator=MaximumLikelihoodEstimator)"
      ],
      "metadata": {
        "id": "LLbHXpN5Wi8I"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Perform Inference\n",
        "\n",
        "After fitting the model, perform inference as shown previously."
      ],
      "metadata": {
        "id": "PmNbjG7bWqxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Define the inference object\n",
        "inference = VariableElimination(model)\n",
        "\n",
        "# Example observations extracted from the transcript\n",
        "observations = {'ActiveIng': 1, 'Food': 0, 'Quantity': 1}\n",
        "\n",
        "# Perform inference to find the probability of Effectiveness\n",
        "prob_effectiveness = inference.query(variables=['Effectiveness'], evidence=observations)\n",
        "print(f\"Probability of Effectiveness: {prob_effectiveness}\")\n",
        "\n",
        "# Perform inference to find the probability of Types of Effects\n",
        "prob_types_of_effects = inference.query(variables=['TypesOfEffects'], evidence=observations)\n",
        "print(f\"Probability of Types of Effects: {prob_types_of_effects}\")\n",
        "\n",
        "# Generate explanations\n",
        "explanation_effectiveness = f\"Given the Active Ingredient, Food, and Quantity, the probability of Effectiveness being high is {prob_effectiveness.values[1]:.2f}.\"\n",
        "explanation_types_of_effects = f\"Given the Effectiveness, the Active Ingredient, and the Food, the probability of having significant Types of Effects is {prob_types_of_effects.values[1]:.2f}.\"\n",
        "\n",
        "print(f\"Explanation for Effectiveness: {explanation_effectiveness}\")\n",
        "print(f\"Explanation for Types of Effects: {explanation_types_of_effects}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiXA4A1_Wocr",
        "outputId": "3f0b8c41-e7e9-4db1-fa40-541964c1c7c4"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of Effectiveness: +------------------+----------------------+\n",
            "| Effectiveness    |   phi(Effectiveness) |\n",
            "+==================+======================+\n",
            "| Effectiveness(0) |               0.0000 |\n",
            "+------------------+----------------------+\n",
            "| Effectiveness(1) |               1.0000 |\n",
            "+------------------+----------------------+\n",
            "Probability of Types of Effects: +-------------------+-----------------------+\n",
            "| TypesOfEffects    |   phi(TypesOfEffects) |\n",
            "+===================+=======================+\n",
            "| TypesOfEffects(0) |                1.0000 |\n",
            "+-------------------+-----------------------+\n",
            "| TypesOfEffects(1) |                0.0000 |\n",
            "+-------------------+-----------------------+\n",
            "Explanation for Effectiveness: Given the Active Ingredient, Food, and Quantity, the probability of Effectiveness being high is 1.00.\n",
            "Explanation for Types of Effects: Given the Effectiveness, the Active Ingredient, and the Food, the probability of having significant Types of Effects is 0.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gboTepOiWvkL"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now onto the text parsing aspect"
      ],
      "metadata": {
        "id": "Cs0Sw83sgdro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Preprocessing:\n",
        "\n",
        "* Tokenization\n",
        "* Named Entity Recognition (NER)\n",
        "* Part-of-Speech (POS) Tagging"
      ],
      "metadata": {
        "id": "BBgAsNoTgh_F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V2T424SDmD-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy"
      ],
      "metadata": {
        "id": "eYwXPL_HmBzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install spaCy and Download a Model\n",
        "\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_lg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81t9lZcWghAa",
        "outputId": "fe5d4eff-280b-4bbf-973c-42769790ad52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m459.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "def categorize_text(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Initialize categories\n",
        "    food = None\n",
        "    quantity = None\n",
        "    effectiveness = None\n",
        "    types_of_effects = None\n",
        "\n",
        "    # Iterate over tokens in the document\n",
        "    for token in doc:\n",
        "        # Check for food category\n",
        "        if token.text.lower() in [\"meat\", \"veggie\"]:\n",
        "            food = 0 if token.text.lower() == \"meat\" else 1\n",
        "\n",
        "        # Check for quantity category\n",
        "        if token.text.lower() in [\"little\", \"lot\"]:\n",
        "            quantity = 0 if token.text.lower() == \"little\" else 1\n",
        "\n",
        "        # Check for effectiveness category\n",
        "        if token.text.lower() in [\"low\", \"high\"]:\n",
        "            effectiveness = 0 if token.text.lower() == \"low\" else 1\n",
        "\n",
        "        # Check for types of effects category\n",
        "        if token.text.lower() in [\"negative\", \"positive\"]:\n",
        "            types_of_effects = 0 if token.text.lower() == \"negative\" else 1\n",
        "\n",
        "    return food, quantity, effectiveness, types_of_effects\n"
      ],
      "metadata": {
        "id": "kNe4oefGgzX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"The meal contained a lot of meat and had a high effectiveness with positive effects.\"\n",
        "text2 = \"The veggie dish was served in little quantity and had a low effectiveness with negative effects.\"\n",
        "\n",
        "food1, quantity1, effectiveness1, types_of_effects1 = categorize_text(text1)\n",
        "food2, quantity2, effectiveness2, types_of_effects2 = categorize_text(text2)\n",
        "\n",
        "print(f\"Text 1: Food={food1}, Quantity={quantity1}, Effectiveness={effectiveness1}, Types of Effects={types_of_effects1}\")\n",
        "print(f\"Text 2: Food={food2}, Quantity={quantity2}, Effectiveness={effectiveness2}, Types of Effects={types_of_effects2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKoYnBgIg5QZ",
        "outputId": "9ae70ce3-02ec-4672-9e83-758b2e52efa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: Food=0, Quantity=1, Effectiveness=1, Types of Effects=1\n",
            "Text 2: Food=1, Quantity=0, Effectiveness=0, Types of Effects=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZK7rstTEr99M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see it's working ok, but it's not super flexible"
      ],
      "metadata": {
        "id": "4kFu8dPgmMhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's use similarity scores"
      ],
      "metadata": {
        "id": "DLRdrbKhmG9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use Hugging Face Transformers for state-of-the-art NLP models that can handle named entity recognition (NER), relation extraction, and more.\n",
        "Stanford CoreNLP provides various NLP tools including NER, dependency parsing, and relation extraction.\n",
        "AllenNLP is built on PyTorch, it offers extensive tools for NLP including pre-trained models for NER and relation extraction."
      ],
      "metadata": {
        "id": "WKmePAzkmlgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Define category vectors\n",
        "food_vectors = {\n",
        "    \"meat\": nlp(\"meat\").vector,\n",
        "    \"veggie\": nlp(\"vegetable\").vector\n",
        "}\n",
        "\n",
        "quantity_vectors = {\n",
        "    \"little\": nlp(\"small\").vector,\n",
        "    \"lot\": nlp(\"large\").vector\n",
        "}\n",
        "\n",
        "effectiveness_vectors = {\n",
        "    \"low\": nlp(\"low\").vector,\n",
        "    \"high\": nlp(\"high\").vector\n",
        "}\n",
        "\n",
        "types_of_effects_vectors = {\n",
        "    \"negative\": nlp(\"negative\").vector,\n",
        "    \"positive\": nlp(\"positive\").vector\n",
        "}\n"
      ],
      "metadata": {
        "id": "IfzJfUvLmJAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_word(word):\n",
        "    word_vector = nlp(word).vector\n",
        "\n",
        "    # Initialize categories\n",
        "    food = None\n",
        "    quantity = None\n",
        "    effectiveness = None\n",
        "    types_of_effects = None\n",
        "\n",
        "    # Calculate similarity scores for each category\n",
        "    food_scores = {category: nlp(word).similarity(nlp(category)) for category in food_vectors}\n",
        "    quantity_scores = {category: nlp(word).similarity(nlp(category)) for category in quantity_vectors}\n",
        "    effectiveness_scores = {category: nlp(word).similarity(nlp(category)) for category in effectiveness_vectors}\n",
        "    types_of_effects_scores = {category: nlp(word).similarity(nlp(category)) for category in types_of_effects_vectors}\n",
        "\n",
        "    # Assign categories based on the highest similarity score\n",
        "    if food_scores:\n",
        "        food = max(food_scores, key=food_scores.get)\n",
        "    if quantity_scores:\n",
        "        quantity = max(quantity_scores, key=quantity_scores.get)\n",
        "    if effectiveness_scores:\n",
        "        effectiveness = max(effectiveness_scores, key=effectiveness_scores.get)\n",
        "    if types_of_effects_scores:\n",
        "        types_of_effects = max(types_of_effects_scores, key=types_of_effects_scores.get)\n",
        "\n",
        "    return food, quantity, effectiveness, types_of_effects\n"
      ],
      "metadata": {
        "id": "9wN9v4ClmLut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"carrot\", \"dog\", \"steak\", \"tiny\", \"enormous\", \"effective\", \"ineffective\", \"beneficial\", \"harmful\"]\n",
        "\n",
        "for word in words:\n",
        "    food, quantity, effectiveness, types_of_effects = categorize_word(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Food: {food}\")\n",
        "    print(f\"Quantity: {quantity}\")\n",
        "    print(f\"Effectiveness: {effectiveness}\")\n",
        "    print(f\"Types of Effects: {types_of_effects}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfukxBILmSgQ",
        "outputId": "3d62eac4-c236-4bd1-8c99-378eac5ffe89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: carrot\n",
            "Food: veggie\n",
            "Quantity: little\n",
            "Effectiveness: low\n",
            "Types of Effects: negative\n",
            "\n",
            "Word: dog\n",
            "Food: meat\n",
            "Quantity: little\n",
            "Effectiveness: low\n",
            "Types of Effects: positive\n",
            "\n",
            "Word: steak\n",
            "Food: meat\n",
            "Quantity: little\n",
            "Effectiveness: low\n",
            "Types of Effects: negative\n",
            "\n",
            "Word: tiny\n",
            "Food: meat\n",
            "Quantity: little\n",
            "Effectiveness: low\n",
            "Types of Effects: negative\n",
            "\n",
            "Word: enormous\n",
            "Food: meat\n",
            "Quantity: little\n",
            "Effectiveness: high\n",
            "Types of Effects: negative\n",
            "\n",
            "Word: effective\n",
            "Food: meat\n",
            "Quantity: little\n",
            "Effectiveness: high\n",
            "Types of Effects: negative\n",
            "\n",
            "Word: ineffective\n",
            "Food: meat\n",
            "Quantity: little\n",
            "Effectiveness: low\n",
            "Types of Effects: negative\n",
            "\n",
            "Word: beneficial\n",
            "Food: meat\n",
            "Quantity: little\n",
            "Effectiveness: high\n",
            "Types of Effects: negative\n",
            "\n",
            "Word: harmful\n",
            "Food: meat\n",
            "Quantity: little\n",
            "Effectiveness: low\n",
            "Types of Effects: negative\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hoILAJ2WsjWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, this works a little better."
      ],
      "metadata": {
        "id": "3EQ7lVLYs3BN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VEHG-xos4vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining the Parsing and the bayes net"
      ],
      "metadata": {
        "id": "-2VZNdjws8cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Define category vectors\n",
        "active_ingredient_vectors = {\n",
        "    \"charcoal\": nlp(\"charcoal\").vector,\n",
        "    \"poppy\": nlp(\"poppy\").vector\n",
        "}\n",
        "\n",
        "food_vectors = {\n",
        "    \"meat\": nlp(\"meat\").vector,\n",
        "    \"veggie\": nlp(\"vegetable\").vector\n",
        "}\n",
        "\n",
        "quantity_vectors = {\n",
        "    \"little\": nlp(\"small\").vector,\n",
        "    \"lot\": nlp(\"large\").vector\n",
        "}\n",
        "\n",
        "effectiveness_vectors = {\n",
        "    \"low\": nlp(\"low\").vector,\n",
        "    \"high\": nlp(\"high\").vector\n",
        "}\n",
        "\n",
        "types_of_effects_vectors = {\n",
        "    \"negative\": nlp(\"negative\").vector,\n",
        "    \"positive\": nlp(\"positive\").vector\n",
        "}\n",
        "\n",
        "def categorize_word(word):\n",
        "    word_vector = nlp(word).vector\n",
        "\n",
        "    # Initialize categories\n",
        "    active_ingredient = None\n",
        "    food = None\n",
        "    quantity = None\n",
        "    effectiveness = None\n",
        "    types_of_effects = None\n",
        "\n",
        "    # Calculate similarity scores for each category\n",
        "    active_ingredient_scores = {category: nlp(word).similarity(nlp(category)) for category in active_ingredient_vectors}\n",
        "    food_scores = {category: nlp(word).similarity(nlp(category)) for category in food_vectors}\n",
        "    quantity_scores = {category: nlp(word).similarity(nlp(category)) for category in quantity_vectors}\n",
        "    effectiveness_scores = {category: nlp(word).similarity(nlp(category)) for category in effectiveness_vectors}\n",
        "    types_of_effects_scores = {category: nlp(word).similarity(nlp(category)) for category in types_of_effects_vectors}\n",
        "\n",
        "    # Assign categories based on the highest similarity score\n",
        "    if active_ingredient_scores:\n",
        "        active_ingredient = 0 if max(active_ingredient_scores, key=active_ingredient_scores.get) == \"charcoal\" else 1\n",
        "    if food_scores:\n",
        "        food = 0 if max(food_scores, key=food_scores.get) == \"meat\" else 1\n",
        "    if quantity_scores:\n",
        "        quantity = 0 if max(quantity_scores, key=quantity_scores.get) == \"little\" else 1\n",
        "    if effectiveness_scores:\n",
        "        effectiveness = 0 if max(effectiveness_scores, key=effectiveness_scores.get) == \"low\" else 1\n",
        "    if types_of_effects_scores:\n",
        "        types_of_effects = 0 if max(types_of_effects_scores, key=types_of_effects_scores.get) == \"negative\" else 1\n",
        "\n",
        "    return active_ingredient, food, quantity, effectiveness, types_of_effects\n",
        "\n",
        "def parse_text(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Initialize categories\n",
        "    active_ingredient = None\n",
        "    food = None\n",
        "    quantity = None\n",
        "    effectiveness = None\n",
        "    types_of_effects = None\n",
        "\n",
        "    # Categorize words in the text\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\":\n",
        "            word_active_ingredient, word_food, word_quantity, word_effectiveness, word_types_of_effects = categorize_word(token.text)\n",
        "\n",
        "            if word_active_ingredient is not None:\n",
        "                active_ingredient = word_active_ingredient\n",
        "            if word_food is not None:\n",
        "                food = word_food\n",
        "            if word_quantity is not None:\n",
        "                quantity = word_quantity\n",
        "            if word_effectiveness is not None:\n",
        "                effectiveness = word_effectiveness\n",
        "            if word_types_of_effects is not None:\n",
        "                types_of_effects = word_types_of_effects\n",
        "\n",
        "    return active_ingredient, food, quantity, effectiveness, types_of_effects\n",
        "\n",
        "# Example usage\n",
        "text = \"The meal consisted of a small portion of steak with an active ingredient, which had a low effectiveness and negative effects.\"\n",
        "active_ingredient, food, quantity, effectiveness, types_of_effects = parse_text(text)\n",
        "\n",
        "# Format the results for the Bayesian network\n",
        "observations = {}\n",
        "if active_ingredient is not None:\n",
        "    observations['ActiveIng'] = active_ingredient\n",
        "if food is not None:\n",
        "    observations['Food'] = food\n",
        "if quantity is not None:\n",
        "    observations['Quantity'] = quantity\n",
        "# if effectiveness is not None:\n",
        "#     observations['Effectiveness'] = effectiveness\n",
        "# if types_of_effects is not None:\n",
        "    # observations['TypesOfEffects'] = types_of_effects\n",
        "\n",
        "print(\"Observations for the Bayesian network:\")\n",
        "print(observations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPwXEuT2tB2k",
        "outputId": "3aaaac8e-9201-4101-e176-45bdb7751357"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observations for the Bayesian network:\n",
            "{'ActiveIng': 0, 'Food': 0, 'Quantity': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fq4eDXRetU0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference to find the probability of Effectiveness\n",
        "prob_effectiveness = inference.query(variables=['Effectiveness'], evidence=observations)\n",
        "print(f\"\\nProbability of Effectiveness based on the Bayesian network:\")\n",
        "print(prob_effectiveness)\n",
        "\n",
        "# Perform inference to find the probability of Types of Effects\n",
        "prob_types_of_effects = inference.query(variables=['TypesOfEffects'], evidence=observations)\n",
        "print(f\"\\nProbability of Types of Effects based on the Bayesian network:\")\n",
        "print(prob_types_of_effects)\n",
        "\n",
        "# Compare the text suggestions with the probabilities\n",
        "text_effectiveness = 0 if effectiveness == 0 else 1\n",
        "text_types_of_effects = 0 if types_of_effects == 0 else 1\n",
        "\n",
        "prob_text_effectiveness = prob_effectiveness.values[text_effectiveness]\n",
        "prob_text_types_of_effects = prob_types_of_effects.values[text_types_of_effects]\n",
        "\n",
        "print(\"\\nComparison of text suggestions and probabilities:\")\n",
        "print(f\"Effectiveness:\")\n",
        "print(f\"  Text suggests: {'Low' if text_effectiveness == 0 else 'High'}\")\n",
        "print(f\"  Probability of the text suggestion being true: {prob_text_effectiveness:.2f}\")\n",
        "\n",
        "print(f\"\\nTypes of Effects:\")\n",
        "print(f\"  Text suggests: {'Negative' if text_types_of_effects == 0 else 'Positive'}\")\n",
        "print(f\"  Probability of the text suggestion being true: {prob_text_types_of_effects:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehybt3hJtEjk",
        "outputId": "ad1547ba-c533-48f1-e455-3ae587168373"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probability of Effectiveness based on the Bayesian network:\n",
            "+------------------+----------------------+\n",
            "| Effectiveness    |   phi(Effectiveness) |\n",
            "+==================+======================+\n",
            "| Effectiveness(0) |               0.0000 |\n",
            "+------------------+----------------------+\n",
            "| Effectiveness(1) |               1.0000 |\n",
            "+------------------+----------------------+\n",
            "\n",
            "Probability of Types of Effects based on the Bayesian network:\n",
            "+-------------------+-----------------------+\n",
            "| TypesOfEffects    |   phi(TypesOfEffects) |\n",
            "+===================+=======================+\n",
            "| TypesOfEffects(0) |                1.0000 |\n",
            "+-------------------+-----------------------+\n",
            "| TypesOfEffects(1) |                0.0000 |\n",
            "+-------------------+-----------------------+\n",
            "\n",
            "Comparison of text suggestions and probabilities:\n",
            "Effectiveness:\n",
            "  Text suggests: Low\n",
            "  Probability of the text suggestion being true: 0.00\n",
            "\n",
            "Types of Effects:\n",
            "  Text suggests: Negative\n",
            "  Probability of the text suggestion being true: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanations"
      ],
      "metadata": {
        "id": "MrH3PCrp1fXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate explanations\n",
        "print(\"\\nExplanations:\")\n",
        "\n",
        "# Find the parent nodes of Effectiveness\n",
        "effectiveness_contributors = model.get_parents('Effectiveness')\n",
        "print(\"effectiveness_contributors\", effectiveness_contributors)\n",
        "print(\"prob_effectiveness\", prob_effectiveness)\n",
        "effectiveness_contributions = []\n",
        "for var in effectiveness_contributors:\n",
        "    print(\"var\", var)\n",
        "    if var in observations:\n",
        "        prob_with_evidence = inference.query(variables=['Effectiveness'], evidence={var: observations[var]}).values[1]\n",
        "        print(\"prob_with_evidence\", prob_with_evidence)\n",
        "        print(\"inference.query(variables=['Effectiveness'], evidence={var: observations[var]}).values[1]\", inference.query(variables=['Effectiveness'], evidence={var: observations[var]}).values[1])\n",
        "        prob_without_evidence = inference.query(variables=['Effectiveness']).values[1]\n",
        "        contribution = prob_with_evidence - prob_without_evidence\n",
        "        effectiveness_contributions.append((var, contribution))\n",
        "\n",
        "if effectiveness_contributions:\n",
        "    most_influential_var_eff, most_influential_contrib_eff = max(effectiveness_contributions, key=lambda x: abs(x[1]))\n",
        "    if most_influential_contrib_eff != 0:\n",
        "        print(f\"The variable that contributes the most to Effectiveness is {most_influential_var_eff} with a change in probability of {most_influential_contrib_eff:.2f}.\")\n",
        "    else:\n",
        "        print(f\"No variables significantly contribute to Effectiveness based on the given observations.\")\n",
        "else:\n",
        "    print(\"No variables significantly contribute to Effectiveness based on the given observations.\")\n",
        "\n",
        "# Find the parent nodes of TypesOfEffects\n",
        "types_of_effects_contributors = model.get_parents('TypesOfEffects')\n",
        "print(\"types_of_effects_contributors\", types_of_effects_contributors)\n",
        "types_of_effects_contributions = []\n",
        "for var in types_of_effects_contributors:\n",
        "    if var in observations:\n",
        "        prob_with_evidence = inference.query(variables=['TypesOfEffects'], evidence={var: observations[var]}).values[1]\n",
        "        prob_without_evidence = inference.query(variables=['TypesOfEffects']).values[1]\n",
        "        contribution = prob_with_evidence - prob_without_evidence\n",
        "        types_of_effects_contributions.append((var, contribution))\n",
        "\n",
        "if types_of_effects_contributions:\n",
        "    most_influential_var_toe, most_influential_contrib_toe = max(types_of_effects_contributions, key=lambda x: abs(x[1]))\n",
        "    if most_influential_contrib_toe != 0:\n",
        "        print(f\"The variable that contributes the most to Types of Effects is {most_influential_var_toe} with a change in probability of {most_influential_contrib_toe:.2f}.\")\n",
        "    else:\n",
        "        print(f\"No variables significantly contribute to Types of Effects based on the given observations.\")\n",
        "else:\n",
        "    print(\"No variables significantly contribute to Types of Effects based on the given observations.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLzEs7EytQzH",
        "outputId": "561c297f-4165-4d07-ec9e-777bd71bca96"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Explanations:\n",
            "effectiveness_contributors ['ActiveIng', 'Food', 'Quantity']\n",
            "prob_effectiveness +------------------+----------------------+\n",
            "| Effectiveness    |   phi(Effectiveness) |\n",
            "+==================+======================+\n",
            "| Effectiveness(0) |               0.0000 |\n",
            "+------------------+----------------------+\n",
            "| Effectiveness(1) |               1.0000 |\n",
            "+------------------+----------------------+\n",
            "var ActiveIng\n",
            "prob_with_evidence 0.8\n",
            "inference.query(variables=['Effectiveness'], evidence={var: observations[var]}).values[1] 0.8\n",
            "var Food\n",
            "prob_with_evidence 0.8\n",
            "inference.query(variables=['Effectiveness'], evidence={var: observations[var]}).values[1] 0.8\n",
            "var Quantity\n",
            "prob_with_evidence 0.6\n",
            "inference.query(variables=['Effectiveness'], evidence={var: observations[var]}).values[1] 0.6\n",
            "The variable that contributes the most to Effectiveness is ActiveIng with a change in probability of 0.20.\n",
            "types_of_effects_contributors ['Effectiveness', 'ActiveIng', 'Food']\n",
            "The variable that contributes the most to Types of Effects is ActiveIng with a change in probability of -0.20.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Z4HFjFv1iOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}